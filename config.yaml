batch_size: 256
num_workers: 4
experiment_name: 07dec_supervised
epochs: 50
optimizer: adamw # or sgd
lr: 0.001
weight_decay: 0.00005
momentum: 0.9 # only for sgd
scheduler: reduceonplateau # or cosineannealing
warmup_epochs: 5
dataset:
  train: RML22_train.h5
  val: RML22_val.h5
checkpoint: false
# pretrained: /path/to/pretrained.pth
# freeze: true
classes:
  0: 8psk
  1: am-dsb
  2: bpsk
  3: cpfsk
  4: gfsk
  5: pam4
  6: qam16
  7: qam64
  8: qpsk
  9: wbfm
nclasses: 10
